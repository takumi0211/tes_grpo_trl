2025-10-29 19:40:59,731 | INFO | train_grpo | LoRA target parameters enumerated (0): all linear layers
2025-10-29 19:40:59,732 | INFO | train_grpo | Trainable LoRA parameters (192): ['base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight shape=(4, 2880)', 'base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight shape=(4096, 4)', 'base_model.model.model.layers.0.self_attn.k_proj.lora_A.default.weight shape=(4, 2880)', 'base_model.model.model.layers.0.self_attn.k_proj.lora_B.default.weight shape=(512, 4)', 'base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight shape=(4, 2880)', 'base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight shape=(512, 4)', 'base_model.model.model.layers.0.self_attn.o_proj.lora_A.default.weight shape=(4, 4096)', 'base_model.model.model.layers.0.self_attn.o_proj.lora_B.default.weight shape=(2880, 4)', 'base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight shape=(4, 2880)', 'base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight shape=(4096, 4)', 'base_model.model.model.layers.1.self_attn.k_proj.lora_A.default.weight shape=(4, 2880)', 'base_model.model.model.layers.1.self_attn.k_proj.lora_B.default.weight shape=(512, 4)', 'base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight shape=(4, 2880)', 'base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight shape=(512, 4)', 'base_model.model.model.layers.1.self_attn.o_proj.lora_A.default.weight shape=(4, 4096)', 'base_model.model.model.layers.1.self_attn.o_proj.lora_B.default.weight shape=(2880, 4)', 'base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight shape=(4, 2880)', 'base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight shape=(4096, 4)', 'base_model.model.model.layers.2.self_attn.k_proj.lora_A.default.weight shape=(4, 2880)', 'base_model.model.model.layers.2.self_attn.k_proj.lora_B.default.weight shape=(512, 4)'] ... (+172 more)
2025-10-29 19:41:00,435 | INFO | train_grpo | StepStream configured | prompts_per_step=4 | num_generations=4 | dataset_rows=30 | keep_keys=['reward_action_0', 'reward_action_1', 'reward_action_2', 'reward_action_3', 'prompt']
2025-10-29 19:41:00,437 | INFO | train_grpo | Generation config | num_generations=4 | generation_batch_size=16 | per_device_train_batch_size=16 | split_batches=True | total_completions_per_step=16
2025-10-29 20:09:37,208 | INFO | train_grpo | LoRA target parameters enumerated (0): all linear layers
2025-10-29 20:09:37,209 | INFO | train_grpo | Trainable LoRA parameters (192): ['base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight shape=(4, 2880)', 'base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight shape=(4096, 4)', 'base_model.model.model.layers.0.self_attn.k_proj.lora_A.default.weight shape=(4, 2880)', 'base_model.model.model.layers.0.self_attn.k_proj.lora_B.default.weight shape=(512, 4)', 'base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight shape=(4, 2880)', 'base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight shape=(512, 4)', 'base_model.model.model.layers.0.self_attn.o_proj.lora_A.default.weight shape=(4, 4096)', 'base_model.model.model.layers.0.self_attn.o_proj.lora_B.default.weight shape=(2880, 4)', 'base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight shape=(4, 2880)', 'base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight shape=(4096, 4)', 'base_model.model.model.layers.1.self_attn.k_proj.lora_A.default.weight shape=(4, 2880)', 'base_model.model.model.layers.1.self_attn.k_proj.lora_B.default.weight shape=(512, 4)', 'base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight shape=(4, 2880)', 'base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight shape=(512, 4)', 'base_model.model.model.layers.1.self_attn.o_proj.lora_A.default.weight shape=(4, 4096)', 'base_model.model.model.layers.1.self_attn.o_proj.lora_B.default.weight shape=(2880, 4)', 'base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight shape=(4, 2880)', 'base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight shape=(4096, 4)', 'base_model.model.model.layers.2.self_attn.k_proj.lora_A.default.weight shape=(4, 2880)', 'base_model.model.model.layers.2.self_attn.k_proj.lora_B.default.weight shape=(512, 4)'] ... (+172 more)
2025-10-29 20:09:38,285 | INFO | train_grpo | StepStream configured | prompts_per_micro_step=1 | num_generations=4 | dataset_rows=30 | keep_keys=['reward_action_0', 'reward_action_1', 'reward_action_2', 'reward_action_3', 'prompt']
2025-10-29 20:09:38,289 | INFO | train_grpo | Generation config | num_generations=4 | generation_batch_size=4 | per_device_train_batch_size=4 | grad_accum=4 | split_batches=True | completions_per_micro_step=4 | completions_per_update=16
